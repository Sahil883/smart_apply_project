posted_date,job_link,source,description
12-06-2025,https://in.linkedin.com/jobs/view/data-engineer-i-at-mckinsey-company-4248144439?position=6&pageNum=0&refId=tWbUOB5G2Au3sJCikcMrvg%3D%3D&trackingId=9%2FklcQpU9048a2PgEbiCAg%3D%3D,LinkedIn,"Who You'll Work WithDriving lasting impact and building long-term capabilities with our clients is not easy work. You are the kind of person who thrives in a high performance/high reward culture - doing hard things, picking yourself up when you stumble, and having the resilience to try another way forward.In return for your drive, determination, and curiosity, we'll provide the resources, mentorship, and opportunities you need to become a stronger leader faster than you ever thought possible. Your colleagues—at all levels—will invest deeply in your development, just as much as they invest in delivering exceptional results for clients. Every day, you'll receive apprenticeship, coaching, and exposure that will accelerate your growth in ways you won’t find anywhere else.When you join us, you will haveContinuous learning Our learning and apprenticeship culture, backed by structured programs, is all about helping you grow while creating an environment where feedback is clear, actionable, and focused on your development. The real magic happens when you take the input from others to heart and embrace the fast-paced learning experience, owning your journey.A voice that matters From day one, we value your ideas and contributions. You’ll make a tangible impact by offering innovative ideas and practical solutions. We not only encourage diverse perspectives, but they are critical in driving us toward the best possible outcomes.Global community With colleagues across 65+ countries and over 100 different nationalities, our firm’s diversity fuels creativity and helps us come up with the best solutions for our clients. Plus, you’ll have the opportunity to learn from exceptional colleagues with diverse backgrounds and experiences.World-class benefits On top of a competitive salary (based on your location, experience, and skills), we provide a comprehensive benefits package, which includes medical, dental, mental health, and vision coverage for you, your spouse/partner, and children.Your ImpactAs a Data Engineer I at McKinsey & Company, you will play a key role in designing, building, and deploying scalable data pipelines and infrastructure that enable our analytics and AI solutions.You will work closely with product managers, developers, asset owners, and client stakeholders to turn raw data into trusted, structured, and high-quality datasets used in decision-making and advanced analytics.Your core responsibilities will includeDeveloping robust, scalable data pipelines for ingesting, transforming, and storing data from multiple structured and unstructured sources using Python/SQL.Creating and optimizing data models and data warehouses to support reporting, analytics, and application integration.Working with cloud-based data platforms (AWS, Azure, or GCP) to build modern, efficient, and secure data solutions.Contributing to R&D projects and internal asset development.Contributing to infrastructure automation and deployment pipelines using containerization and CI/CD tools.Collaborating across disciplines to integrate data engineering best practices into broader analytical and generative AI (gen AI) workflows.Supporting and maintaining data assets deployed in client environments with a focus on reliability, scalability, and performance.Furthermore, you will have opportunity to explore and contribute to solutions involving generative AI, such as vector embeddings, retrieval-augmented generation (RAG), semantic search, and LLM-based prompting, especially as we integrate gen AI capabilities into our broader data ecosystem.Your Qualifications and SkillsBachelor’s degree in computer science, engineering, mathematics, or a related technical field (or equivalent practical experience).3+ years of experience in data engineering, analytics engineering, or a related technical role.Strong Python programming skills with demonstrated experience building scalable data workflows and ETL/ELT pipelines.Proficient in SQL with experience designing normalized and denormalized data models.Hands-on experience with orchestration tools such as Airflow, Kedro, or Azure Data Factory (ADF).Familiarity with cloud platforms (AWS, Azure, or GCP) for building and managing data infrastructure.Discernable communication skills, especially around breaking down complex structures into digestible and relevant points for a diverse set of clients and colleagues, at all levels.High-value personal qualities including critical thinking and creative problem-solving skills; an ability to influence and work in teams.Entrepreneurial mindset and ownership mentality are must; desire to learn and develop, within a dynamic, self-led organization.Hands-on experience with containerization technologies (Docker, Docker-compose).Hands on experience with automation frameworks (Github Actions, CircleCI, Jenkins, etc.).Exposure to generative AI tools or concepts (e.g., OpenAI, Cohere, embeddings, vector databases).Experience working in Agile teams and contributing to design and architecture discussions.Contributions to open-source projects or active participation in data engineering communities.Show moreShow less"
23-05-2025,https://in.linkedin.com/jobs/view/data-engineer-ii-t500-18133-at-mcdonald-s-4235908514?position=5&pageNum=0&refId=tWbUOB5G2Au3sJCikcMrvg%3D%3D&trackingId=mhviriELRLzYsBvQK19klg%3D%3D,LinkedIn,"About McDonald’s:One of the world’s largest employers with locations in more than 100 countries, McDonald’s Corporation has corporate opportunities in Hyderabad. Our global offices serve as dynamic innovation and operations hubs, designed to expand McDonald's global talent base and in-house expertise. Our new office in Hyderabad will bring together knowledge across business, technology, analytics, and AI, accelerating our ability to deliver impactful solutions for the business and our customers across the globe.Who we’re looking for:Primary Responsibilities:Builds and maintains relevant and reliable data products that support Finance Analytics. Develops and implements new technology solutions as needed to ensure ongoing improvement with data reliability and observability in-view.Participates in new software development and data engineering initiatives supporting Finance Analytics, ensuring timely and accurate delivery of financial data products.Drive and implement best Data Engineering practices for pipeline development, data governance, data security and quality across financial datasets.Implement security and privacy controls in data workflows, ensuring compliance with finance regulatory requirements.Monitor, troubleshoot, and improve performance and reliability of existing finance data pipeline infrastructure.Staying up to date with emerging data engineering technologies, trends, and best practices, and evaluating their applicability to meet evolving financial analytics needs.Documenting data engineering processes, workflows, and solutions for knowledge sharing and future reference.Partner and collaborate with data engineers, particularly in finance-centric data models and processing frameworks.Ability and flexibility to coordinate and work with teams distributed across time zones, as needed.Skill:Applies technical data engineering expertise to develop reliable pipelines and improve data quality in support of finance and analytics initiativesBachelor's or master's degree in computer science or related engineering field and deep experience with Cloud computing3+ years of professional experience in data engineering or related fieldsProficiency in Python, Java, or Scala for data processing and automationHands-on experience with data orchestration tools (e.g., Apache Airflow, Luigi) and big data ecosystems (e.g., Hadoop, Spark, NoSQL)Good working knowledge of Data quality functions like cleansing, standardization, parsing, de-duplication, mapping, hierarchy management, etc.Ability to perform extensive data analysis (comparing multiple datasets) using a variety of toolsEffective communication and stakeholder management skills to drive alignment and adoption of data engineering standardsDemonstrated experience in data management & data governance capabilitiesFamiliarity with data warehousing principles and best practices.Excellent problem solver - use of data and technology to solve problems or answer complex data related questionsExcellent collaboration skills to work effectively in cross-functional teamsWork location:Hyderabad, IndiaWork hours:Work pattern:Full time role.Work mode:Hybrid.Show moreShow less"
10-06-2025,https://in.linkedin.com/jobs/view/data-engineer-associate-systems-engineer-at-autozone-4246224917?position=7&pageNum=0&refId=tWbUOB5G2Au3sJCikcMrvg%3D%3D&trackingId=2%2Fd%2FM6rAgqQAVD%2Fd9X8h8Q%3D%3D,LinkedIn,"About AutoZone:AutoZone is the nation's leading retailer and a leading distributor of automotive replacement parts and accessories with more than 6,000 stores in US, Puerto Rico, Mexico, and Brazil. Each store carries an extensive line for cars, sport utility vehicles, vans and light trucks, including new and remanufactured hard parts, maintenance items and accessories.We also sell automotive diagnostic and repair software through ALLDATA, diagnostic and repair information through ALLDATAdiy.com, automotive accessories through AutoAnything.com and auto and light truck parts and accessories through AutoZone.com.Since opening its first store in Forrest City, Ark. on July 4, 1979, the company has joined the New York Stock Exchange (NYSE: AZO) and earned a spot in the Fortune 500.AutoZone has been committed to providing the best parts, prices, and customer service in the automotive aftermarket industry. We have a rich culture and history of going the Extra Mile for our customers and our community. At AutoZone you’re not just doing a job; you’re playing a crucial role in creating a better experience for our customers, while creating opportunities to DRIVE YOUR CAREER almost anywhere! We are looking for talented people who are customer focused, enjoy helping others and have the DRIVE to excel in a fast-paced environment!Position SummaryThe Systems Engineer will design data model solutions and ensure alignment between business and IT strategies, operating models, guiding principles, and software development with a focus on the information layer. The Systems Engineer works across business lines and IT domains to ensure that information is viewed as a corporate asset. This includes its proper data definition, creation, usage, archival, and governance. The Systems Engineer works with other engineers and Data Architects to design overall solutions in accordance with industry best practices, principles and standards. The Systems Engineer strives to create and improve the quality of systems, provide more flexible solutions, and reduce time-to-market.Key ResponsibilitiesEnhance and maintain the AutoZone information strategy.Ensure alignment of programs and projects with the strategic AZ Information Roadmap and related strategiesPerform gap analysis between current data structures and target data structures.Enhance and maintain the Enterprise Information ModelWork with service architects and application architects to assist with the creation of proper data access and utilization methods.Gather complex business requirements and translate product and project needs into data models supporting long-term solutions.Serve as a technical data strategy expert and lead the creation of technical requirements and design deliverables.Define and communicate data standards, industry best practices, technologies, and architectures.Check conformance to standards and resolve any conflicts by explaining and justifying architectural decisions.Recommend and evaluate new tools and methodologies as needed.Manage, communicate, and improve the data governance framework.Requirements:A systems thinker, able to move fluidly between high-level abstract thinking and detail-oriented implementation, open minded to new ideas, approaches, and technologiesA data and fact-driven decision maker, with an ability to make quick decisions under uncertainty when necessary; able to quickly learn new technologies, tools, and organizational structures/strategiesUnderstanding of current industry standard best practices regarding integration, architecture, tools, and processesA self-starter that is naturally inquisitive, requiring only small pieces to the puzzle, across many technologies – new and legacyExcellent written and verbal communication, presentation, and analytical skills, including the ability to effectively communicate complex technical concepts and designs to a broad range of people.Education and/or ExperienceBachelor's degree in MIS, Computer Science or similar degree or experience requiredMinimum 3+ yrs experience and knowledge of database systems such as Oracle, Postgres, UDB/DB2, BigQuery, Spanner, JSON, and CouchbaseMinimum 2 years of experience with data requirements gathering, acquisition of data from difference business systems, ingestion of data in GCP using managed services namely BigQuery, DataFlow, Composer, Pub/Sub and other ingestion technologies, curation of the data using DBT or other similar technologies and creating data marts/wide tables for analysis and reporting consumption.Assembling large, complex sets of data that meet non-functional and functional business requirementsIdentifying, designing, and implementing internal process improvements including re-designing infrastructure for greater scalability, optimizing data delivery, and automating manual processesBuilding required infrastructure for optimal extraction, transformation and loading of data from various data sources using GCP and SQL technologiesBuilding analytical tools to utilize the data pipeline, providing actionable insight into key business performance metrics including operational efficiency and customer acquisition.Working with stakeholders including data, design, product, and executive teams and assisting them with data-related technical issuesWorking with stakeholders including the Executive, Product, Data and Design teams to support their data infrastructure needs while assisting with data-related technical issues.Relational & NoSQL database design capability across OLTP & OLAPExcellent analytical and problem-solving skillsExcellent verbal and written communication skillsAbility to facilitate modeling sessions and communicate appropriately with IT and business customersExperience with Agile software development methodologiesExperience with large-replicated databases across distributed and cloud data centersOur Values:An AutoZoner Always.....PUTS CUSTOMERS FIRSTCARES ABOUT PEOPLESTRIVES FOR EXCEPTIONAL PERFORMANCEENERGIZES OTHERSEMBRACES DIVERSITYHELPS TEAMS SUCCEEDShow moreShow less"
10-06-2025,https://in.linkedin.com/jobs/view/data-engineer-itc-at-nike-4248306425?position=4&pageNum=0&refId=tWbUOB5G2Au3sJCikcMrvg%3D%3D&trackingId=qMq2kR1QlqOpftoCRqN%2Bsg%3D%3D,LinkedIn,"Who You’ll Work WithA data engineer will work in the Data and Artificial Intelligence organisation of Nike and will focus on building highly complex and performant data pipelines that'll drive Nike's data driven strategies for the future of sports.Who We Are Looking ForIn this role, we are looking for self-driven individuals who have deep technical knowledge in the big data domain. This role requires the individual to be an excellent problem solver who'll design and implement complex data pipelines which solve business problems of Nike.The core competencies required for this role include -Bachelor’s degree in computer science engineering2+ years of hands-on experience in data engineering fieldIn depth big data tech stack knowledgeExpertise in pyspark and SQLExpertise in databricks, snowflake, airflowExcellent written and verbal communication skillsWhat You’ll Work OnAs a data engineer you'll be a key pillar of the data engineering team. You will collaborate closely with other engineers to deliver key changes to data pipelines that drive Nike's data strategyOn a day-to-day basis, you'll focus on -Building, enhancing, and troubleshooting complex data pipelinesCollaborating with product managers, engineers, analysts to build, enhance and troubleshoot data pipelinesCollaborate with senior, lead and principal engineers to define and implement quality standards across data pipelinesContribute towards the design and architecture of data pipelinesImplement data quality and reliability measures across data pipelinesShow moreShow less"
30-05-2025,https://in.linkedin.com/jobs/view/data-engineer-at-box8-4240914373?position=1&pageNum=0&refId=tWbUOB5G2Au3sJCikcMrvg%3D%3D&trackingId=wP%2FJHWCgWErFnT8bsgRGaQ%3D%3D,LinkedIn,"We are looking for a passionate and curious Data Engineer (Entry-Level) to join our DataTech team. This is an excellent opportunity for fresh graduates or early-career professionals to build a strong foundation in data engineering by working on real-world data problems, building robust pipelines, and collaborating across teams.ResponsibilitiesAssist in developing scalable and optimized data pipelines for extraction, transformation, and loading (ETL).Write clean and efficient Python scripts and SQL queries for data processing and analysis.Work on integrating multiple data sources (databases, APIs, flat files, etc. )Support team members in ensuring data quality, accuracy, and consistency.Collaborate with analysts, data scientists, and engineers to deliver data solutions.Contribute to automation initiatives and help build internal data tools.Participate in code reviews, documentation, and team meetings to learn best practices in software and data engineering.Assist in building computer vision or different AI models.RequirementsB. E. /B. Tech in Computer Science, Information Technology, or related field (Tier I college background is a plus).Strong foundation in: Python (Pandas, NumPy, basic scripting), SQL (writing basic to intermediate queries).Exposure to: Git and Linux Shell Scripting, Data visualization tools or dashboards (e. g., Tableau, Power BI - optional).Bonus if you've explored tools like Airflow, BigQuery, AWS S3/Redshift, or Firebase.Built projects or done internships related to data engineering, analytics, or backend systems.Strong logical thinking, curiosity to learn, and willingness to dive into data problems.This job was posted by Payal Verma from Box8.Show moreShow less"
10-06-2025,https://in.linkedin.com/jobs/view/data-engineer-itc-at-nike-4248306288?position=2&pageNum=0&refId=tWbUOB5G2Au3sJCikcMrvg%3D%3D&trackingId=oplfYx5TIz2dF17GNX5JBg%3D%3D,LinkedIn,"Who You’ll Work WithThis role is part of the Nike’s Content Technology team within Consumer Product and Innovation (CP&I) organization, working very closely with the globally distributed Engineering and Product teams. This role will roll up to the Director Software Engineering based out of Nike India Tech Centre.Who We Are Looking ForWe are looking for experienced Technology focused and hands on Lead Engineer to join our team in Bengaluru, India.As a Senior Data Engineer, you will play a key role in ensuring that our data products are robust and capable of supporting our Data Engineering and Business Intelligence initiatives.A data engineer with 2+ years of experience in data engineering.Proficient in SQL, Python, PySpark, and Apache Airflow (or similar workflow management tools).Hands-on experience with Databricks, Snowflake, and cloud platforms (AWS/GCP/Azure).Good understanding of Spark, Delta Lake, Medallion architecture, and ETL/ELT processes.Solid data modeling and data profiling skills.Familiarity with Agile methodologies (Scrum/Kanban).Awareness of DevOps practices in data engineering (automated testing, security administration, workflow orchestration)Exposure to Kafka or real-time data processingStrong communication and collaboration skills.Preferred:familiarity with Tableau or similar BI toolsexposure to GenAI/ML pipelinesNice to have: Databricks certifications for data engineer, developer, or Apache Spark.What You’ll Work OnBuild and maintain ETL/ELT pipelines and reusable data components.Collaborate with peers and stakeholders to gather data requirements.Participate in code reviews and contribute to quality improvements.Monitor and troubleshoot data pipelines for performance and reliability.Support CI/CD practices in data engineering workflows.Show moreShow less"
